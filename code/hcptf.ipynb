{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hcptf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hcptf.py\n",
    "# %load bptf.py\n",
    "\n",
    "\"\"\"\n",
    "Bayesian Poisson tensor factorization with variational inference.\n",
    "\"\"\"\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.random as rn\n",
    "import scipy.special as sp\n",
    "import sktensor as skt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from path import path\n",
    "from argparse import ArgumentParser\n",
    "from utils import *\n",
    "\n",
    "\n",
    "class BPTF(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_modes=4, n_components=100,  max_iter=200, tol=0.0001,\n",
    "                 smoothness=100, verbose=True, alpha=0.1, debug=False):\n",
    "        self.n_modes = n_modes\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.smoothness = smoothness\n",
    "        self.verbose = verbose\n",
    "        self.debug = debug\n",
    "\n",
    "        self.alpha = alpha                                      # shape hyperparameter\n",
    "        self.beta_M = np.ones(self.n_modes, dtype=float)        # rate hyperparameter (inferred)\n",
    "\n",
    "        self.gamma_DK_M = np.empty(self.n_modes, dtype=object)  # variational shapes\n",
    "        self.delta_DK_M = np.empty(self.n_modes, dtype=object)  # variational rates\n",
    "\n",
    "        self.E_DK_M = np.empty(self.n_modes, dtype=object)      # arithmetic expectations\n",
    "        self.G_DK_M = np.empty(dtself.n_modes, dtype=object)      # geometric expectations\n",
    "\n",
    "        # Inference cache\n",
    "        self.sumE_MK = np.empty((self.n_modes, self.n_components), dtype=float)\n",
    "        self.zeta = None\n",
    "        self.nz_recon_I = None\n",
    "\n",
    "    def _reconstruct_nz(self, subs_I_M):\n",
    "        \"\"\"Computes the reconstruction for only non-zero entries.\"\"\"\n",
    "        I = subs_I_M[0].size\n",
    "        K = self.n_components\n",
    "        nz_recon_IK = np.ones((I, K))\n",
    "        for m in xrange(self.n_modes):\n",
    "            nz_recon_IK *= self.G_DK_M[m][subs_I_M[m], :]\n",
    "        self.nz_recon_I = nz_recon_IK.sum(axis=1)\n",
    "        return self.nz_recon_I\n",
    "\n",
    "    def _elbo(self, data, mask=None):\n",
    "        \"\"\"Computes the Evidence Lower Bound (ELBO).\"\"\"\n",
    "        if mask is None:\n",
    "            uttkrp_K = self.sumE_MK.prod(axis=0)\n",
    "        elif isinstance(mask, skt.dtensor):\n",
    "            uttkrp_DK = mask.uttkrp(self.E_DK_M, 0)\n",
    "            uttkrp_K = (self.E_DK_M[0] * uttkrp_DK).sum(axis=0)\n",
    "        elif isinstance(mask, skt.sptensor):\n",
    "            uttkrp_DK = sp_uttkrp(mask.vals, mask.subs, 0, self.G_DK_M)\n",
    "            uttkrp_K = (self.E_DK_M[0] * uttkrp_DK).sum(axis=0)\n",
    "\n",
    "        bound = uttkrp_K.sum()\n",
    "\n",
    "        if isinstance(data, skt.dtensor):\n",
    "            subs_I_M = data.nonzero()\n",
    "            vals_I = data[subs_I_M]\n",
    "        elif isinstance(data, skt.sptensor):\n",
    "            subs_I_M = data.subs\n",
    "            vals_I = data.vals\n",
    "        nz_recon_I = self._reconstruct_nz(subs_I_M)\n",
    "\n",
    "        bound -= np.log(vals_I + 1).sum()\n",
    "        bound += (vals_I * np.log(nz_recon_I)).sum()\n",
    "\n",
    "        K = self.n_components\n",
    "        for m in xrange(self.n_modes):\n",
    "            D = self.mode_dims[m]\n",
    "            shp = self.alpha\n",
    "            rte = self.alpha * self.beta_M[m]\n",
    "            gamma_DK = self.gamma_DK_M[m]\n",
    "            delta_DK = self.delta_DK_M[m]\n",
    "\n",
    "            bound += (shp - 1.) * (np.log(self.G_DK_M[m]).sum())\n",
    "            bound -= rte * (self.sumE_MK[m, :].sum())\n",
    "            bound -= K * D * (sp.gammaln(shp) - shp * np.log(rte))\n",
    "            bound += (-(gamma_DK - 1.) * sp.psi(gamma_DK) - np.log(delta_DK)\n",
    "                      + gamma_DK + sp.gammaln(gamma_DK)).sum()\n",
    "        return bound\n",
    "\n",
    "    def _init_all_components(self, mode_dims):\n",
    "        assert len(mode_dims) == self.n_modes\n",
    "        self.mode_dims = mode_dims\n",
    "        for m, D in enumerate(mode_dims):\n",
    "            self._init_component(m, D)\n",
    "\n",
    "    def _init_component(self, m, dim):\n",
    "        assert self.mode_dims[m] == dim\n",
    "        K = self.n_components\n",
    "        if not self.debug:\n",
    "            s = self.smoothness\n",
    "            gamma_DK = s * rn.gamma(s, 1. / s, size=(dim, K))\n",
    "            delta_DK = s * rn.gamma(s, 1. / s, size=(dim, K))\n",
    "        else:\n",
    "            gamma_DK = np.ones((dim, K))\n",
    "            delta_DK = np.ones((dim, K))\n",
    "        self.gamma_DK_M[m] = gamma_DK\n",
    "        self.delta_DK_M[m] = delta_DK\n",
    "        self.E_DK_M[m] = gamma_DK / delta_DK\n",
    "        self.sumE_MK[m, :] = self.E_DK_M[m].sum(axis=0)\n",
    "        self.G_DK_M[m] = np.exp(sp.psi(gamma_DK) - np.log(delta_DK))\n",
    "        self.beta_M[m] = 1. / self.E_DK_M[m].mean()\n",
    "\n",
    "    def _check_component(self, m):\n",
    "        assert np.isfinite(self.E_DK_M[m]).all()\n",
    "        assert np.isfinite(self.G_DK_M[m]).all()\n",
    "        assert np.isfinite(self.gamma_DK_M[m]).all()\n",
    "        assert np.isfinite(self.delta_DK_M[m]).all()\n",
    "\n",
    "    def _update_gamma(self, m, data):\n",
    "        if isinstance(data, skt.dtensor):\n",
    "            tmp = data.astype(float)\n",
    "            subs_I_M = data.nonzero()\n",
    "            tmp[subs_I_M] /= self._reconstruct_nz(subs_I_M)\n",
    "            uttkrp_DK = tmp.uttkrp(self.G_DK_M, m)\n",
    "\n",
    "        elif isinstance(data, skt.sptensor):\n",
    "            tmp = data.vals / self._reconstruct_nz(data.subs)\n",
    "            uttkrp_DK = sp_uttkrp(tmp, data.subs, m, self.G_DK_M)\n",
    "\n",
    "        self.gamma_DK_M[m][:, :] = self.alpha + self.G_DK_M[m] * uttkrp_DK\n",
    "\n",
    "    def _update_delta(self, m, mask=None):\n",
    "        if mask is None:\n",
    "            self.sumE_MK[m, :] = 1.\n",
    "            uttrkp_DK = self.sumE_MK.prod(axis=0)\n",
    "        else:\n",
    "            uttrkp_DK = mask.uttkrp(self.E_DK_M, m)\n",
    "        self.delta_DK_M[m][:, :] = self.alpha * self.beta_M[m] + uttrkp_DK\n",
    "\n",
    "    def _update_cache(self, m):\n",
    "        gamma_DK = self.gamma_DK_M[m]\n",
    "        delta_DK = self.delta_DK_M[m]\n",
    "        self.E_DK_M[m] = gamma_DK / delta_DK\n",
    "        self.sumE_MK[m, :] = self.E_DK_M[m].sum(axis=0)\n",
    "        self.G_DK_M[m] = np.exp(sp.psi(gamma_DK)) / delta_DK\n",
    "\n",
    "    def _update_beta(self, m):\n",
    "        self.beta_M[m] = 1. / self.E_DK_M[m].mean()\n",
    "\n",
    "    def _update(self, data, mask=None, modes=None):\n",
    "        if modes is not None:\n",
    "            modes = list(set(modes))\n",
    "        else:\n",
    "            modes = range(self.n_modes)\n",
    "        assert all(m in range(self.n_modes) for m in modes)\n",
    "\n",
    "        curr_elbo = -np.inf\n",
    "        for itn in xrange(self.max_iter):\n",
    "            s = time.time()\n",
    "            for m in modes:\n",
    "                self._update_gamma(m, data)\n",
    "                self._update_delta(m, mask)\n",
    "                self._update_cache(m)\n",
    "                self._update_beta(m)  # must come after cache update!\n",
    "                self._check_component(m)\n",
    "            bound = self._elbo(data, mask=mask)\n",
    "            delta = (bound - curr_elbo) / abs(curr_elbo) if itn > 0 else np.nan\n",
    "            e = time.time() - s\n",
    "            if self.verbose:\n",
    "                print 'ITERATION %d:\\t\\\n",
    "                       Time: %f\\t\\\n",
    "                       Objective: %.2f\\t\\\n",
    "                       Change: %.5f\\t'\\\n",
    "                       % (itn, e, bound, delta)\n",
    "            assert ((delta >= 0.0) or (itn == 0))\n",
    "            curr_elbo = bound\n",
    "            if delta < self.tol:\n",
    "                break\n",
    "\n",
    "    def set_component(self, m, E_DK, G_DK, gamma_DK, delta_DK):\n",
    "        assert E_DK.shape[1] == self.n_components\n",
    "        self.E_DK_M[m] = E_DK.copy()\n",
    "        self.sumE_MK[m, :] = E_DK.sum(axis=0)\n",
    "        self.G_DK_M[m] = G_DK.copy()\n",
    "        self.gamma_DK_M[m] = gamma_DK.copy()\n",
    "        self.delta_DK_M[m] = delta_DK.copy()\n",
    "        self.beta_M[m] = 1. / E_DK.mean()\n",
    "\n",
    "    def set_component_like(self, m, model, subs_D=None):\n",
    "        assert model.n_modes == self.n_modes\n",
    "        assert model.n_components == self.n_components\n",
    "        D = model.E_DK_M[m].shape[0]\n",
    "        if subs_D is None:\n",
    "            subs_D = np.arange(D)\n",
    "        assert min(subs_D) >= 0 and max(subs_D) < D\n",
    "        E_DK = model.E_DK_M[m][subs_D, :].copy()\n",
    "        G_DK = model.G_DK_M[m][subs_D, :].copy()\n",
    "        gamma_DK = model.gamma_DK_M[m][subs_D, :].copy()\n",
    "        delta_DK = model.delta_DK_M[m][subs_D, :].copy()\n",
    "        self.set_component(m, E_DK, G_DK, gamma_DK, delta_DK)\n",
    "\n",
    "    def fit(self, data, mask=None):\n",
    "        assert data.ndim == self.n_modes\n",
    "        data = preprocess(data)\n",
    "        if mask is not None:\n",
    "            mask = preprocess(mask)\n",
    "            assert data.shape == mask.shape\n",
    "            assert is_binary(mask)\n",
    "            assert np.issubdtype(mask.dtype, int)\n",
    "        self._init_all_components(data.shape)\n",
    "        self._update(data, mask=mask)\n",
    "        return self\n",
    "\n",
    "    def transform(self, modes, data, mask=None, version='geometric'):\n",
    "        \"\"\"Transform new data given a pre-trained model.\"\"\"\n",
    "        assert all(m in range(self.n_modes) for m in modes)\n",
    "        assert (version == 'geometric') or (version == 'arithmetic')\n",
    "\n",
    "        assert data.ndim == self.n_modes\n",
    "        data = preprocess(data)\n",
    "        if mask is not None:\n",
    "            mask = preprocess(mask)\n",
    "            assert data.shape == mask.shape\n",
    "            assert is_binary(mask)\n",
    "            assert np.issubdtype(mask.dtype, int)\n",
    "        self.mode_dims = data.shape\n",
    "        for m, D in enumerate(self.mode_dims):\n",
    "            if m not in modes:\n",
    "                if self.E_DK_M[m].shape[0] != D:\n",
    "                    raise ValueError('Pre-trained components dont match new data.')\n",
    "            else:\n",
    "                self._init_component(m, D)\n",
    "        self._update(data, mask=mask, modes=modes)\n",
    "\n",
    "        if version == 'geometric':\n",
    "            return [self.G_DK_M[m] for m in modes]\n",
    "        elif version == 'arithmetic':\n",
    "            return [self.E_DK_M[m] for m in modes]\n",
    "\n",
    "    def fit_transform(self, modes, data, mask=None, version='geometric'):\n",
    "        assert all(m in range(self.n_modes) for m in modes)\n",
    "        assert (version == 'geometric') or (version == 'arithmetic')\n",
    "\n",
    "        self.fit(data, mask=mask)\n",
    "\n",
    "        if version == 'geometric':\n",
    "            return [self.G_DK_M[m] for m in modes]\n",
    "        elif version == 'arithmetic':\n",
    "            return [self.E_DK_M[m] for m in modes]\n",
    "\n",
    "    def reconstruct(self, mask=None, version='geometric'):\n",
    "        \"\"\"Reconstruct data using point estimates of latent factors.\n",
    "\n",
    "        Currently supported only up to 5-way tensors.\n",
    "        \"\"\"\n",
    "        assert (version == 'geometric') or (version == 'arithmetic')\n",
    "        if version == 'geometric':\n",
    "            tmp = [G_DK.copy() for G_DK in self.G_DK_M]\n",
    "        elif version == 'arithmetic':\n",
    "            tmp = [E_DK.copy() for E_DK in self.E_DK_M]\n",
    "\n",
    "        if weights.keys():\n",
    "            assert all(m in range(self.n_modes) for m in weights.keys())\n",
    "            for m, weight_matrix in weights.iteritems():\n",
    "                tmp[m] = weight_matrix\n",
    "        Y_pred = parafac(tmp)\n",
    "        if drop_diag:\n",
    "            diag_idx = np.identity(Y_pred.shape[0]).astype(bool)\n",
    "            Y_pred[diag_idx] = 0\n",
    "        return Y_pred\n",
    "\n",
    "\n",
    "def main():\n",
    "    p = ArgumentParser()\n",
    "    p.add_argument('-d', '--data', type=path, required=True)\n",
    "    p.add_argument('-o', '--out', type=path, required=True)\n",
    "    p.add_argument('-m', '--mask', type=path, default=None)\n",
    "    p.add_argument('-k', '--n_components', type=int, required=True)\n",
    "    p.add_argument('-n', '--max_iter', type=int, default=200)\n",
    "    p.add_argument('-t', '--tol', type=float, default=1e-4)\n",
    "    p.add_argument('-s', '--smoothness', type=int, default=100)\n",
    "    p.add_argument('-a', '--alpha', type=float, default=0.1)\n",
    "    p.add_argument('-v', '--verbose', action=\"store_true\", default=False)\n",
    "    p.add_argument('--debug', action=\"store_true\", default=False)\n",
    "    args = p.parse_args()\n",
    "\n",
    "    args.out.makedirs_p()\n",
    "    assert args.data.exists() and args.out.exists()\n",
    "    if args.data.ext == '.npz':\n",
    "        data_dict = np.load(args.data)\n",
    "        if 'data' in data_dict.files:\n",
    "            data = data_dict['data']\n",
    "        elif 'Y' in data_dict.files:\n",
    "            data = data_dict['Y']\n",
    "        if data.dtype == 'object':\n",
    "            assert data.size == 1\n",
    "            data = data[0]\n",
    "    else:\n",
    "        data = np.load(args.data)\n",
    "\n",
    "    valid_types = [np.ndarray, skt.dtensor, skt.sptensor]\n",
    "    assert any(isinstance(data, vt) for vt in valid_types)\n",
    "\n",
    "    mask = None\n",
    "    if args.mask is not None:\n",
    "        if args.mask.ext == '.npz':\n",
    "            mask = np.load(args.mask)['mask']\n",
    "            if mask.dtype == 'object':\n",
    "                assert mask.size == 1\n",
    "                mask = mask[0]\n",
    "        else:\n",
    "            mask = np.load(args.mask)\n",
    "\n",
    "        assert any(isinstance(mask, vt) for vt in valid_types)\n",
    "        assert mask.shape == data.shape\n",
    "\n",
    "    bptf = BPTF(n_modes=data.ndim,\n",
    "                n_components=args.n_components,\n",
    "                max_iter=args.max_iter,\n",
    "                tol=args.tol,\n",
    "                smoothness=args.smoothness,\n",
    "                verbose=args.verbose,\n",
    "                alpha=args.alpha,\n",
    "                debug=args.debug)\n",
    "\n",
    "    bptf.fit(data, mask=mask)\n",
    "    serialize_bptf(bptf, args.out, num=None, desc='trained_model')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bml]",
   "language": "python",
   "name": "conda-env-bml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
